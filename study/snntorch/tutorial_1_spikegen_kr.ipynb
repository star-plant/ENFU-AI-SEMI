{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBNKFLJIobYt"
      },
      "source": [
        "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/snntorch_alpha_w.png?raw=true' width=\"400\">](https://github.com/jeshraghian/snntorch/)\n",
        "\n",
        "# Tutorial 1 - Spike Encoding\n",
        "## By Jason K. Eshraghian (www.ncg.ucsc.edu)\n",
        "\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/jeshraghian/snntorch/blob/master/examples/tutorial_1_spikegen.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/GitHub-Mark-Light-120px-plus.png?raw=true' width=\"28\">](https://github.com/jeshraghian/snntorch/) [<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/GitHub_Logo_White.png?raw=true' width=\"80\">](https://github.com/jeshraghian/snntorch/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4blpfg4y44uO"
      },
      "source": [
        "이 snnTorch 튜토리얼 시리즈는 다음 논문을 기반으로 작성되었습니다. 이 자료나 코드를 작업에 활용하신다면, 아래의 출처를 인용해 주시기 바랍니다.:\n",
        "\n",
        "> <cite> [Jason K. Eshraghian, Max Ward, Emre Neftci, Xinxin Wang, Gregor Lenz, Girish Dwivedi, Mohammed Bennamoun, Doo Seok Jeong, and Wei D. Lu. \"Training Spiking Neural Networks Using Lessons From Deep Learning\". Proceedings of the IEEE, 111(9) September 2023.](https://ieeexplore.ieee.org/abstract/document/10242251) </cite>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnF_PEo5obYv",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "이 튜토리얼에서는 snnTorch를 사용하여 다음 내용을 학습하게 됩니다.:\n",
        "* 데이터셋을 스파이크 데이터셋으로 변환하는 방법,\n",
        "* 변환된 데이터를 시각화하는 방법,\n",
        "* 무작위 스파이크 열(random spike train)을 생성하는 방법."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7qhH_lt8_mn"
      },
      "source": [
        "# Introduction\n",
        "빛은 망막이 광자를 스파이크로 변환할 때 우리가 보게 되는 것입니다. 냄새는 기화된 분자가 스파이크로 변환될 때 우리가 맡게 되는 것입니다. 촉각은 신경 말단이 촉각 압력을 스파이크로 변환할 때 우리가 느끼게 됩니다. 뇌는 *Spike*라는 공통 통화를 사용합니다.\n",
        "\n",
        "최종 목표가 SNN(Spiking Neural Network)을 구축하는 것이라면, 입력 역시 스파이크를 사용하는 것이 타당합니다.\n",
        "물론 Tutorial 3에서 보게 되듯이 비스파이크 입력을 사용하는 경우도 흔하지만, 데이터를 인코딩하는 매력 중 일부는 생물학적인 처리 과정을 모사하는 데 있습니다.\n",
        "\n",
        "\n",
        "\n",
        "1.   **Spikes**: (a-b) 생물학적 뉴런은 약 100 mV 진폭의 전기적 충격(spike)을 통해 정보를 처리하고 전달합니다. (c) 많은 뉴런의 계산 모델은 이러한 전압 펄스를 단일 비트 이벤트(‘1’ 또는 ‘0’)로 단순화합니다. 이는 고정밀 값을 사용하는 것보다 하드웨어에서 훨씬 간단하게 표현할 수 있습니다.\n",
        "\n",
        "2.   **Sparsity**: (c) 뉴런은 대부분의 시간을 안정 상태로 보내며, 어느 시점이든 대부분의 활성화를 0으로 유지합니다. 0이 많은 희소 벡터/텐서는 저장 비용이 저렴할 뿐 아니라, 예를 들어 희소 활성화 값을 시냅스 가중치와 곱해야 한다고 할 때, 대부분의 값이 ‘0’이면 네트워크 파라미터를 메모리에서 읽을 필요가 거의 없습니다. 이는 뉴로모픽 하드웨어가 매우 효율적으로 동작할 수 있음을 의미합니다.\n",
        "\n",
        "3.   **Static-Suppression (a.k.a, event-driven processing**: (d-e) 감각 주변부는 처리할 새로운 정보가 있을 때만 정보를 처리합니다. (e)의 각 픽셀은 조도(illuminance)의 변화에만 반응하므로, 이미지 대부분이 차단됩니다. 전통적인 신호 처리 방식에서는 모든 채널/픽셀이 전역 샘플링 속도나 셔터 속도를 따라야 하기 때문에 센싱 빈도가 느려집니다. 이벤트 기반 처리는 변하지 않는 입력을 차단함으로써 희소성과 전력 효율성을 높일 뿐만 아니라, 더 빠른 처리 속도를 가능하게 합니다.\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/3s.png?raw=true' width=\"600\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGNOnFM4DzHY"
      },
      "source": [
        "이 튜토리얼에서는 non-spiking 형태의 입력 데이터(예: MNIST 데이터셋)를 가지고 있다고 가정하고, 이를 몇 가지 다른 기법을 사용하여 스파이크로 인코딩하는 과정을 다룹니다.\n",
        "그럼 시작해봅시다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAbXmmVN50Pl"
      },
      "source": [
        "먼저, snnTorch의 최신 PyPi 배포판을 설치합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxLoYgkhobYw",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "!pip install snntorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6E7VH5kbTmA"
      },
      "source": [
        "## 1. Setting up the MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Suffg8_ZobYw",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 1.1. Import packages and setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cR9okh0jobYx",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import snntorch as snn\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4LPD0WCobYx",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Training Parameters\n",
        "batch_size=128\n",
        "data_path='/tmp/data/mnist'\n",
        "num_classes = 10  # MNIST has 10 output classes\n",
        "\n",
        "# Torch Variables\n",
        "dtype = torch.float"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5X2a5a9obYy"
      },
      "source": [
        "### 1.2 Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlbY8Rm9obYy",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform\n",
        "transform = transforms.Compose([\n",
        "            transforms.Resize((28,28)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0,), (1,))])\n",
        "\n",
        "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZyzEp9YHgPb"
      },
      "source": [
        "If the above code block throws an error, e.g. the MNIST servers are down, then uncomment the following code instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpGLLVqeHgwy"
      },
      "outputs": [],
      "source": [
        "# # temporary dataloader if MNIST service is unavailable\n",
        "# !wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "# !tar -zxvf MNIST.tar.gz\n",
        "\n",
        "# mnist_train = datasets.MNIST(root = './', train=True, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5wXl2bVobYz",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Until we actually start training a network, we won't need large datasets.\n",
        "`snntorch.utils` contains a few useful functions for modifying datasets. Apply `data_subset` to reduce the dataset by the factor defined in `subset`. *E.g., for `subset=10`, a training set of 60,000 will be reduced to 6,000.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FPsPU46obYz",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from snntorch import utils\n",
        "\n",
        "subset = 10\n",
        "mnist_train = utils.data_subset(mnist_train, subset)\n",
        "print(f\"The size of mnist_train is {len(mnist_train)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CedMagsobY0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 1.3 Create DataLoaders\n",
        "The Dataset objects created above load data into memory, and the DataLoader will serve it up in batches. DataLoaders in PyTorch are a handy interface for passing data into a network. They return an iterator divided up into mini-batches of size ``batch_size``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrJLlWj2obY0",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwSdczxKobY0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## 2. Spike Encoding\n",
        "\n",
        "Spiking Neural Networks (SNNs) are made to exploit time-varying data. And yet, MNIST is not a time-varying dataset.\n",
        "There are two options for using MNIST with an SNN:\n",
        "\n",
        "1. Repeatedly pass the same training sample $\\mathbf{X}\\in\\mathbb{R}^{m\\times n}$ to the network at each time step. This is like converting MNIST into a static, unchanging video. Each element of $\\mathbf{X}$ can take a high precision value normalized between 0 and 1: $X_{ij}\\in [0, 1]$.\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_1_static.png?raw=true' width=\"700\">\n",
        "</center>\n",
        "\n",
        "2. Convert the input into a spike train of sequence length `num_steps`, where each feature/pixel takes on a discrete value $X_{i,j} \\in \\{0, 1\\}$.\n",
        "In this case, MNIST is converted into a time-varying sequence of spikes that features a relation to the original image.\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_2_spikeinput.png?raw=true' width=\"700\">\n",
        "</center>\n",
        "\n",
        "The first method is quite straightforward, and does not fully exploit the temporal dynamics of SNNs. So let’s consider data-to-spike conversion (encoding) from (2) in more detail.\n",
        "\n",
        "The module `snntorch.spikegen` (i.e., spike generation) contains a series of functions that simplify the conversion of data into spikes. There are currently three options available for spike encoding in `snntorch`:\n",
        "\n",
        "1. Rate coding: [`spikegen.rate`](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html#snntorch.spikegen.rate)\n",
        "2. Latency coding: [`spikegen.latency`](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html#snntorch.spikegen.latency)\n",
        "3. Delta modulation: [`spikegen.delta`](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html#snntorch.spikegen.delta)\n",
        "\n",
        "How do these differ?\n",
        "\n",
        "\n",
        "1.   *Rate coding* uses input features to determine spiking **frequency**\n",
        "2.   *Latency coding* uses input features to determine spike **timing**\n",
        "3.   *Delta modulation* uses the temporal **change** of input features to generate spikes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D5HSoY4bQDm"
      },
      "source": [
        "### 2.1 Rate coding of MNIST\n",
        "\n",
        "One example of converting input data into a rate code is as follows.\n",
        "Each normalised input feature $X_{ij}$ is used as the probability an event (spike) occurs at any given time step, returning a rate-coded value $R_{ij}$. This can be treated as a Bernoulli trial: $R_{ij}\\sim B(n,p)$, where the number of trials is $n=1$, and the probability of success (spiking) is $p=X_{ij}$. Explicitly, the probability a spike occurs is:\n",
        "\n",
        "$${\\rm P}(R_{ij}=1) = X_{ij} = 1 - {\\rm P}(R_{ij} = 0)$$\n",
        "\n",
        "Create a vector filled with the value '0.5' and encode it using the above technique:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxorUvomL1ei"
      },
      "outputs": [],
      "source": [
        "# Temporal Dynamics\n",
        "num_steps = 10\n",
        "\n",
        "# create vector filled with 0.5\n",
        "raw_vector = torch.ones(num_steps)*0.5\n",
        "\n",
        "# pass each sample through a Bernoulli trial\n",
        "rate_coded_vector = torch.bernoulli(raw_vector)\n",
        "print(f\"Converted vector: {rate_coded_vector}\")\n",
        "\n",
        "print(f\"The output is spiking {rate_coded_vector.sum()*100/len(rate_coded_vector):.2f}% of the time.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0E8Z8mSNflV"
      },
      "source": [
        "Now try again, but increasing the length of `raw_vector`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6uUgpktNjBg"
      },
      "outputs": [],
      "source": [
        "num_steps = 100\n",
        "\n",
        "# create vector filled with 0.5\n",
        "raw_vector = torch.ones(num_steps)*0.5\n",
        "\n",
        "# pass each sample through a Bernoulli trial\n",
        "rate_coded_vector = torch.bernoulli(raw_vector)\n",
        "print(f\"The output is spiking {rate_coded_vector.sum()*100/len(rate_coded_vector):.2f}% of the time.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoLxfVoINzdH"
      },
      "source": [
        "As `num_steps`$\\rightarrow\\infty$, the proportion of spikes approaches the original raw value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYKsWmoGLz6S"
      },
      "source": [
        "For an MNIST image, this probability of spiking corresponds to the pixel value. A white pixel corresponds to a 100% probability of spiking, and a black pixel will never generate a spike. Take a look at the 'Rate Coding' column below for further intuition.\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_3_spikeconv.png?raw=true' width=\"1000\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8_Lzm6FOcm0"
      },
      "source": [
        "In a similar way, `spikegen.rate` can be used to generate a rate-coded sample of data. As each sample of MNIST is just an image, we can use `num_steps` to repeat it across time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nz70JGXqobY1",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from snntorch import spikegen\n",
        "\n",
        "# Iterate through minibatches\n",
        "data = iter(train_loader)\n",
        "data_it, targets_it = next(data)\n",
        "\n",
        "# Spiking Data\n",
        "spike_data = spikegen.rate(data_it, num_steps=num_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0hATEwKobY1",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "If the input falls outside of $[0,1]$, this no longer represents a probability. Such cases are automatically clipped to ensure the feature represents a probability.\n",
        "\n",
        "The structure of the input data is ``[num_steps x batch_size x input dimensions]``:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebdP5kFKobY2",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(spike_data.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cnas5Q89l_10"
      },
      "source": [
        "### 2.2 Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVFuIXxMobY2",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### 2.2.1 Animation\n",
        "snnTorch contains a module [`snntorch.spikeplot`](https://snntorch.readthedocs.io/en/latest/snntorch.spikeplot.html) that simplifies the process of visualizing, plotting, and animating spiking neurons.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TYFlc4_ZK-u"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import snntorch.spikeplot as splt\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwWROIkdobY3",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "To plot one sample of data, index into a single sample from the batch (B) dimension of `spike_data`, ``[T x B x 1 x 28 x 28]``:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZxTqqOlobY3",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "spike_data_sample = spike_data[:, 0, 0]\n",
        "print(spike_data_sample.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJJyPUiuQ61x"
      },
      "source": [
        "`spikeplot.animator` makes it super simple to animate 2-D data.<br>\n",
        "Note: if you are running the notebook locally you may need to install ffmpeg: e.g., `pip install ffmpeg` or if in a Conda environment, `conda install -c conda-forge ffmpeg`.<br>\n",
        "If ffmpeg is not found, please uncomment the line below and modify the path to your ffmpeg.exe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QVyvj9PobY3",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "anim = splt.animator(spike_data_sample, fig, ax)\n",
        "# plt.rcParams['animation.ffmpeg_path'] = 'C:\\\\path\\\\to\\\\your\\\\ffmpeg.exe'\n",
        "\n",
        "HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ko8KJBCNobY4",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# If you're feeling sentimental, you can save the animation: .gif, .mp4 etc.\n",
        "anim.save(\"spike_mnist_test.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu1_f0XZobY4",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "The associated target label can be indexed as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Yb76uofobY4",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(f\"The corresponding target is: {targets_it[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTRqW-wtobY5",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "MNIST features a greyscale image, and the white text guarantees a 100% of spiking at every time step. So let's do that again but reduce the spiking frequency. This can be achieved by setting the argument `gain`. Here, we will reduce spiking frequency to 25%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymxnM4CaobY5",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "spike_data = spikegen.rate(data_it, num_steps=num_steps, gain=0.25)\n",
        "\n",
        "spike_data_sample2 = spike_data[:, 0, 0]\n",
        "fig, ax = plt.subplots()\n",
        "anim = splt.animator(spike_data_sample2, fig, ax)\n",
        "HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dicJdyG2obY5",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Uncomment for optional save\n",
        "# anim.save(\"spike_mnist_test2.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgPZBNIaobY5"
      },
      "source": [
        "Now average the spikes out over time and reconstruct the input images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4ikMCQLobY6",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "plt.figure(facecolor=\"w\")\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(spike_data_sample.mean(axis=0).reshape((28,-1)).cpu(), cmap='binary')\n",
        "plt.axis('off')\n",
        "plt.title('Gain = 1')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(spike_data_sample2.mean(axis=0).reshape((28,-1)).cpu(), cmap='binary')\n",
        "plt.axis('off')\n",
        "plt.title('Gain = 0.25')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bbbI1o2obY7",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "The case where `gain=0.25` is lighter than where `gain=1`, as spiking probability has been reduced by a factor of $\\times 4$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpfpKe3zobY8",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### 2.2.2 Raster Plots\n",
        "Alternatively, we can generate a raster plot of an input sample. This requires reshaping the sample into a 2-D tensor, where 'time' is the first dimension. Pass this sample into the function `spikeplot.raster`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCpsLPySobY8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Reshape\n",
        "spike_data_sample2 = spike_data_sample2.reshape((num_steps, -1))\n",
        "\n",
        "# raster plot\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "splt.raster(spike_data_sample2, ax, s=1.5, c=\"black\")\n",
        "\n",
        "plt.title(\"Input Layer\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Neuron Number\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvhIdrAZobY9",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "The following code snippet shows how to index into one single neuron.\n",
        "Depending on the input data, you may need to try\n",
        "a few different neurons between 0 & 784 before finding one that\n",
        "spikes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3kY3uoOobY9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "idx = 210  # index into 210th neuron\n",
        "\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(8, 1))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "splt.raster(spike_data_sample.reshape(num_steps, -1)[:, idx].unsqueeze(1), ax, s=100, c=\"black\", marker=\"|\")\n",
        "\n",
        "plt.title(\"Input Neuron\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lxp91nlobY-",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### 2.2.3 Summary of Rate Coding\n",
        "The idea of rate coding is actually quite controversial. Although we are fairly confident rate coding takes place at our sensory periphery, we are not convinced that the cortex globally encodes information as spike rates. A couple of compelling reasons why include:\n",
        "\n",
        "*   **Power Consumption:** Nature optimised for efficiency. Multiple spikes are needed to achieve any sort of task, and each spike consumes power. In fact, [Olshausen and Field's work in \"What is the other 85% of V1 doing?\"](http://www.rctn.org/bruno/papers/V1-chapter.pdf) demonstrates that rate-coding can only explain, at most, the activity of 15% of neurons in the primary visual cortex (V1). It is unlikely to be the only mechanism within the brain, which is both resource-constrained and highly efficient.\n",
        "\n",
        "\n",
        "*   **Reaction Response Times:** We know that the reaction time of a human is roughly around 250ms. If the average firing rate of a neuron in the human brain is on the order of 10Hz, then we can only process about 2 spikes within our reaction timescale.\n",
        "\n",
        "So why, then, might we use rate codes if they are not optimal for power efficiency or latency? Even if our brain doesn't process data as a rate, we are fairly sure that our biological sensors do. The power/latency disadvantages are partially offset by showing huge noise robustness: it's fine if some of the spikes fail to generate, because there will be plenty more where they came from.\n",
        "\n",
        "Additionally, you may have heard of the [Hebbian mantra of \"neurons that fire together, wire together\"](https://doi.org/10.2307/1418888). If there is plenty of spiking, this may suggest there is plenty of learning. In some cases where training SNNs proves to be challenging, encouraging more firing via a rate code is one possible solution.\n",
        "\n",
        "Rate coding is almost certainly working in conjunction with other encoding schemes in the brain. We will consider these other encoding mechanisms in the following sections.\n",
        "This covers the `spikegen.rate` function. Further information [can be found in the documentation here](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enzqRvuNobY-",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 2.3 Latency Coding of MNIST\n",
        "Temporal codes capture information about the precise firing time of neurons; a single spike carries much more meaning than in rate codes which rely on firing frequency. While this opens up more susceptibility to noise, it can also decrease the power consumed by the hardware running SNN algorithms by orders of magnitude.\n",
        "\n",
        "`spikegen.latency` is a function that allows each input to fire at most **once** during the full time sweep.\n",
        "Features closer to `1` will fire earlier and features closer to `0` will fire later. I.e., in our MNIST case, bright pixels will fire earlier and dark pixels will fire later.\n",
        "\n",
        "The following block derives how this works. If you've forgotten circuit theory and/or the math means nothing to you, then don't worry! All that matters is: **big** input means **fast** spike; **small** input means **late** spike.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5yZdcX4So-W"
      },
      "source": [
        "---\n",
        "**Optional: Derivation of Latency Code Mechanism**\n",
        "\n",
        "By default, spike timing is calculated by treating the input feature as the current injection $I_{in}$ into an RC circuit. This current moves charge onto the capacitor, which increases $V(t)$. We assume that there is a trigger voltage, $V_{thr}$, which once reached, generates a spike. The question then becomes: *for a given input current (and equivalently, input feature), how long does it take for a spike to be generated?*\n",
        "\n",
        "Starting with Kirchhoff's current law, $I_{in} = I_R + I_C$, the rest of the derivation leads us to a logarithmic relationship between time and the input.\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_4_latencyrc.png?raw=true' width=\"600\">\n",
        "</center>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqJlK7AhjGHw"
      },
      "source": [
        "The following function uses the above result to convert a feature of intensity $X_{ij}\\in [0,1]$ into a latency coded response $L_{ij}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J06UgGHKTkea"
      },
      "outputs": [],
      "source": [
        "def convert_to_time(data, tau=5, threshold=0.01):\n",
        "  spike_time = tau * torch.log(data / (data - threshold))\n",
        "  return spike_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voBg5kujkGFQ"
      },
      "source": [
        "Now, use the above function to visualize the relationship between input feature intensity and its corresponding spike time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52PwqfpKkK-I"
      },
      "outputs": [],
      "source": [
        "raw_input = torch.arange(0, 5, 0.05) # tensor from 0 to 5\n",
        "spike_times = convert_to_time(raw_input)\n",
        "\n",
        "plt.plot(raw_input, spike_times)\n",
        "plt.xlabel('Input Value')\n",
        "plt.ylabel('Spike Time (s)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P972FBhmluv3"
      },
      "source": [
        "The smaller the value, the later the spike occurs with exponential dependence.\n",
        "\n",
        "The vector `spike_times` contains the time at which spikes are triggered, rather than a sparse tensor that contains the spikes themselves (1's and 0's).\n",
        "When running an SNN simulation, we need the 1/0 representation to obtain all of the advantages of using spikes.\n",
        "This whole process can be automated using `spikegen.latency`, where we pass a minibatch from the MNIST dataset in `data_it`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m835u23QobY-",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "spike_data = spikegen.latency(data_it, num_steps=100, tau=5, threshold=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKDPjTvKobY_",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Some of the arguments include:\n",
        "\n",
        "* `tau`:  the RC time constant of the circuit. By default, the input features are treated as a constant current injected into an RC circuit. A higher ``tau`` will induce slower firing.\n",
        "* `threshold`: the membrane potential firing threshold. Input values below this threshold do not have a closed-form solution, as the input current is insufficient to drive the membrane up to the threshold. All values below the threshold are clipped and assigned to the final time step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGH7b49SobY_",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### 2.3.1 Raster plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kypMtfF7obY_",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "splt.raster(spike_data[:, 0].view(num_steps, -1), ax, s=25, c=\"black\")\n",
        "\n",
        "plt.title(\"Input Layer\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Neuron Number\")\n",
        "plt.show()\n",
        "\n",
        "# optional save\n",
        "# fig.savefig('destination_path.png', format='png', dpi=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm1--DHYobZA",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "To make sense of the raster plot, note that high intensity features fire first, whereas low intensity features fire last:\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_5_latencyraster.png?raw=true' width=\"800\">\n",
        "</center>\n",
        "\n",
        "The logarithmic code coupled with the lack of diverse input values (i.e., the lack of midtone/grayscale features) causes significant clustering in two areas of the plot.\n",
        "The bright pixels induce firing at the start of the run, and the dark pixels at the end.\n",
        "We can increase `tau` to slow down the spike times, or linearize the spike times by setting the optional argument `linear=True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZX8azDNWobZA",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "spike_data = spikegen.latency(data_it, num_steps=100, tau=5, threshold=0.01, linear=True)\n",
        "\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "splt.raster(spike_data[:, 0].view(num_steps, -1), ax, s=25, c=\"black\")\n",
        "plt.title(\"Input Layer\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Neuron Number\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZuk6g3NobZB",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "The spread of firing times is much more evenly distributed now. This is achieved by linearizing the logarithmic equation according to the rules shown below. Unlike the RC model, there is no physical basis for the model. It's just simpler.\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_6_latencylinear.png?raw=true' width=\"600\">\n",
        "</center>\n",
        "\n",
        "\n",
        "But note how all firing occurs within the first ~5 time steps, whereas the simulation range is 100 time steps.\n",
        "This indicates that we have a lot of redundant time steps doing nothing. This can be solved by either increasing `tau` to slow down the time constant, or setting the optional argument `normalize=True` to span the full range of `num_steps`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLgntdwSobZB",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "spike_data = spikegen.latency(data_it, num_steps=100, tau=5, threshold=0.01,\n",
        "                              normalize=True, linear=True)\n",
        "\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "splt.raster(spike_data[:, 0].view(num_steps, -1), ax, s=25, c=\"black\")\n",
        "\n",
        "plt.title(\"Input Layer\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Neuron Number\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EFIqaylobZC",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "One major advantage of latency coding over rate coding is sparsity. If neurons are constrained to firing a maximum of once over the time course of interest, then this promotes low-power operation.\n",
        "\n",
        "In the scenario shown above, a majority of the spikes occur at the final time step, where the input features fall below the threshold. In a sense, the dark background of the MNIST sample holds no useful information.\n",
        "\n",
        "We can remove these redundant features by setting `clip=True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uowgb4FPobZC",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "spike_data = spikegen.latency(data_it, num_steps=100, tau=5, threshold=0.01,\n",
        "                              clip=True, normalize=True, linear=True)\n",
        "\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "splt.raster(spike_data[:, 0].view(num_steps, -1), ax, s=25, c=\"black\")\n",
        "\n",
        "plt.title(\"Input Layer\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Neuron Number\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7gN02QOobZC",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "That looks much better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG9erdfxobZD",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "#### 2.3.2 Animation\n",
        "We will run the exact same code block as before to create an animation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjLC1Pl_obZD",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "spike_data_sample = spike_data[:, 0, 0]\n",
        "print(spike_data_sample.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwVwMVpzobZD",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "anim = splt.animator(spike_data_sample, fig, ax)\n",
        "\n",
        "HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FONW5DIkobZE",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "This animation is obviously much tougher to make out in video form, but a keen eye will be able to catch a glimpse of the initial frame where most of the spikes occur.\n",
        "Index into the corresponding target value to check its value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgNLaB90obZD",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Save output: .gif, .mp4 etc.\n",
        "# anim.save(\"mnist_latency.gif\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrqfPu43obZE",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(targets_it[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl93G7LwnG67"
      },
      "source": [
        "That's it for the `spikegen.latency` function. Further information [can be found in the documentation here](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxe0msNpmpcN"
      },
      "source": [
        "### 2.4 Delta Modulation\n",
        "There are theories that the retina is adaptive: it will only process information when there is something new to process. If there is no change in your field of view, then your photoreceptor cells are  less prone to firing.\n",
        "\n",
        "That is to say: **biology is event-driven**. Neurons thrive on change.\n",
        "\n",
        "As a nifty example, a few researchers have dedicated their lives to designing retina-inspired image sensors, for example, the [Dynamic Vision Sensor](https://ieeexplore.ieee.org/abstract/document/7128412/). Although [the attached link is from over a decade ago, the work in this video](https://www.youtube.com/watch?v=6eOM15U_t1M&ab_channel=TobiDelbruck) was ahead of its time.\n",
        "\n",
        "Delta modulation is based on event-driven spiking. The `snntorch.delta` function accepts a time-series tensor as input. It takes the difference between each subsequent feature across all time steps. By default, if the difference is both *positive* and *greater than the threshold $V_{thr}$*, a spike is generated:\n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/examples/tutorial1/1_2_7_delta.png?raw=true' width=\"600\">\n",
        "</center>\n",
        "\n",
        "To illustrate, let's first come up with a contrived example where we create our own input tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AOr1kN-r4n-"
      },
      "outputs": [],
      "source": [
        "# Create a tensor with some fake time-series data\n",
        "data = torch.Tensor([0, 1, 0, 2, 8, -20, 20, -5, 0, 1, 0])\n",
        "\n",
        "# Plot the tensor\n",
        "plt.plot(data)\n",
        "\n",
        "plt.title(\"Some fake time-series data\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Voltage (mV)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih_UJ526tJPo"
      },
      "source": [
        "Pass the above tensor into the `spikegen.delta` function, with an arbitrarily selected `threshold=4`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSNI1zGdtHac"
      },
      "outputs": [],
      "source": [
        "# Convert data\n",
        "spike_data = spikegen.delta(data, threshold=4)\n",
        "\n",
        "# Create fig, ax\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(8, 1))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "# Raster plot of delta converted data\n",
        "splt.raster(spike_data, ax, c=\"black\")\n",
        "\n",
        "plt.title(\"Input Neuron\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.yticks([])\n",
        "plt.xlim(0, len(data))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlmCwN40uPLq"
      },
      "source": [
        "There are three time steps where the difference between $data[T]$ and $data[T+1]$ is greater than or equal to $V_{thr}=4$. This means there are three *on-spikes*.\n",
        "\n",
        "The large dip to $-20$ has not been captured above. If negative swings have importance in your data, you can enable the optional argument `off_spike=True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMrUGhRnuN8e"
      },
      "outputs": [],
      "source": [
        "# Convert data\n",
        "spike_data = spikegen.delta(data, threshold=4, off_spike=True)\n",
        "\n",
        "# Create fig, ax\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(8, 1))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "# Raster plot of delta converted data\n",
        "splt.raster(spike_data, ax, c=\"black\")\n",
        "\n",
        "plt.title(\"Input Neuron\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.yticks([])\n",
        "plt.xlim(0, len(data))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_5FajsDvnEw"
      },
      "source": [
        "We've generated additional spikes, but this isn't actually the full picture!\n",
        "\n",
        "Printing out the tensor will show the presence of \"off-spikes\" which take on a value of `-1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9deHKE2zxGA5"
      },
      "outputs": [],
      "source": [
        "print(spike_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Nz32V0fxm2d"
      },
      "source": [
        "While `spikegen.delta` has only been demonstrated on a fake sample of data, its true use is to compress time-series data by only generating spikes for sufficiently large changes/events.\n",
        "\n",
        "That wraps up the three main spike conversion functions! There are still additional features to each of the three conversion techniques that have not been detailed in this tutorial. In particular, we have only looked at encoding input data; we have not considered how we might encode targets, and when that is necessary. We recommend [referring to the documentation for a deeper dive](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxrGoLIjobZE",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## 3. Spike Generation (Optional)\n",
        "Now what if we don't actually have any data to start with?\n",
        "Say we just want a randomly generated spike train from scratch. Inside of\n",
        "`spikegen.rate` is a nested function, `rate_conv`, which actually performs the  spike conversion step.\n",
        "\n",
        "All we have to do is initialize a randomly generated `torchTensor` to pass in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Q_7uj0vobZE",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Create a random spike train\n",
        "spike_prob = torch.rand((num_steps, 28, 28), dtype=dtype) * 0.5\n",
        "spike_rand = spikegen.rate_conv(spike_prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOy-NZ5YobZF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 3.1 Animation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCIwKN0WobZF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "anim = splt.animator(spike_rand, fig, ax)\n",
        "\n",
        "HTML(anim.to_html5_video())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kx-VKWxFobZF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Save output: .gif, .mp4 etc.\n",
        "# anim.save(\"random_spikes.gif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_IH912xobZF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 3.2 Raster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6QgcKCrobZF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "ax = fig.add_subplot(111)\n",
        "splt.raster(spike_rand[:, 0].view(num_steps, -1), ax, s=25, c=\"black\")\n",
        "\n",
        "plt.title(\"Input Layer\")\n",
        "plt.xlabel(\"Time step\")\n",
        "plt.ylabel(\"Neuron Number\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwEXpWkRy8_N"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-SsITWKobZF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "That's it for spike conversion and generation.\n",
        "This approach generalizes beyond images, to single-dimensional and multi-dimensional tensors.\n",
        "\n",
        "For reference, the documentation for [`spikegen` can be found here](https://snntorch.readthedocs.io/en/latest/snntorch.spikegen.html) and for [`spikeplot`, here](https://snntorch.readthedocs.io/en/latest/snntorch.spikeplot.html)\n",
        "\n",
        "[In the next tutorial](https://snntorch.readthedocs.io/en/latest/tutorials/index.html), you will learn the basics of spiking neurons and how to use them.\n",
        "\n",
        "If you like this project, please consider starring ⭐ the repo on GitHub as it is the easiest and best way to support it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EjmSqPs-VWw"
      },
      "source": [
        "# Additional Resources\n",
        "\n",
        "* [Check out the snnTorch GitHub project here.](https://github.com/jeshraghian/snntorch)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "9QXsrr6Mp5e_",
        "1EWDw3bip8Ie",
        "vFM8UV9CreIX",
        "xXkTAJ9ws1Y6",
        "OgkWg605tE1y",
        "OBt0WDzyujnk",
        "xC96eesMqYo-",
        "mszPTrYOluym",
        "VTHK-wAWV57B"
      ],
      "name": "snntorch_tutorial_1.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "579503e60735c0b0ad61cf404d04af89041cf694c55fa4cc17d05f5d9b483dbc"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}